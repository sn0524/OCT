//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21112126
// Cuda compilation tools, release 8.0, V8.0.43
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_20
.address_size 64

	// .globl	_Z8upfirRowPdS_S_iiii

.visible .entry _Z8upfirRowPdS_S_iiii(
	.param .u64 _Z8upfirRowPdS_S_iiii_param_0,
	.param .u64 _Z8upfirRowPdS_S_iiii_param_1,
	.param .u64 _Z8upfirRowPdS_S_iiii_param_2,
	.param .u32 _Z8upfirRowPdS_S_iiii_param_3,
	.param .u32 _Z8upfirRowPdS_S_iiii_param_4,
	.param .u32 _Z8upfirRowPdS_S_iiii_param_5,
	.param .u32 _Z8upfirRowPdS_S_iiii_param_6
)
{
	.reg .pred 	%p<17>;
	.reg .b32 	%r<65>;
	.reg .f64 	%fd<29>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd3, [_Z8upfirRowPdS_S_iiii_param_0];
	ld.param.u64 	%rd4, [_Z8upfirRowPdS_S_iiii_param_1];
	ld.param.u64 	%rd5, [_Z8upfirRowPdS_S_iiii_param_2];
	ld.param.u32 	%r18, [_Z8upfirRowPdS_S_iiii_param_3];
	ld.param.u32 	%r19, [_Z8upfirRowPdS_S_iiii_param_4];
	ld.param.u32 	%r21, [_Z8upfirRowPdS_S_iiii_param_5];
	ld.param.u32 	%r20, [_Z8upfirRowPdS_S_iiii_param_6];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd5;
	shl.b32 	%r22, %r18, 1;
	add.s32 	%r23, %r22, %r20;
	add.s32 	%r24, %r23, -2;
	mov.u32 	%r25, %ntid.x;
	mov.u32 	%r26, %ctaid.x;
	mov.u32 	%r27, %tid.x;
	mad.lo.s32 	%r1, %r25, %r26, %r27;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mov.u32 	%r30, %tid.y;
	mad.lo.s32 	%r2, %r28, %r29, %r30;
	mov.u32 	%r31, %ntid.z;
	mov.u32 	%r32, %ctaid.z;
	mov.u32 	%r33, %tid.z;
	mad.lo.s32 	%r3, %r31, %r32, %r33;
	setp.lt.s32	%p1, %r1, %r24;
	setp.lt.s32	%p2, %r2, %r19;
	and.pred  	%p3, %p1, %p2;
	setp.lt.s32	%p4, %r3, %r21;
	and.pred  	%p5, %p3, %p4;
	@!%p5 bra 	BB0_13;
	bra.uni 	BB0_1;

BB0_1:
	and.b32  	%r34, %r1, 1;
	setp.eq.b32	%p6, %r34, 1;
	@!%p6 bra 	BB0_7;
	bra.uni 	BB0_2;

BB0_2:
	bfe.s32 	%r35, %r20, 0, 1;
	add.s32 	%r4, %r35, %r20;
	mov.f64 	%fd24, 0d0000000000000000;
	setp.lt.s32	%p7, %r4, 2;
	@%p7 bra 	BB0_12;

	add.s32 	%r37, %r1, -1;
	shr.u32 	%r38, %r37, 31;
	add.s32 	%r39, %r37, %r38;
	shr.s32 	%r5, %r39, 1;
	shr.u32 	%r40, %r4, 31;
	add.s32 	%r41, %r4, %r40;
	shr.s32 	%r6, %r41, 1;
	mad.lo.s32 	%r42, %r3, %r19, %r2;
	mul.lo.s32 	%r7, %r42, %r18;
	mov.f64 	%fd11, 0d0000000000000000;
	mov.u32 	%r63, 0;
	mov.f64 	%fd28, %fd11;

BB0_4:
	sub.s32 	%r9, %r5, %r63;
	setp.gt.s32	%p8, %r9, -1;
	setp.lt.s32	%p9, %r9, %r18;
	and.pred  	%p10, %p8, %p9;
	mov.f64 	%fd27, %fd11;
	@!%p10 bra 	BB0_6;
	bra.uni 	BB0_5;

BB0_5:
	shl.b32 	%r43, %r63, 1;
	mul.wide.s32 	%rd6, %r43, 8;
	add.s64 	%rd7, %rd2, %rd6;
	add.s32 	%r44, %r7, %r9;
	mul.wide.s32 	%rd8, %r44, 8;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.f64 	%fd13, [%rd9];
	ld.global.f64 	%fd14, [%rd7+8];
	mul.f64 	%fd2, %fd14, %fd13;
	mov.f64 	%fd27, %fd2;

BB0_6:
	mov.f64 	%fd3, %fd27;
	add.f64 	%fd28, %fd28, %fd3;
	add.s32 	%r63, %r63, 1;
	setp.lt.s32	%p11, %r63, %r6;
	mov.f64 	%fd24, %fd28;
	@%p11 bra 	BB0_4;
	bra.uni 	BB0_12;

BB0_7:
	and.b32  	%r45, %r20, 1;
	add.s32 	%r11, %r45, %r20;
	mov.f64 	%fd24, 0d0000000000000000;
	setp.lt.s32	%p12, %r11, 2;
	@%p12 bra 	BB0_12;

	shr.u32 	%r47, %r1, 31;
	add.s32 	%r48, %r1, %r47;
	shr.s32 	%r12, %r48, 1;
	shr.u32 	%r49, %r11, 31;
	add.s32 	%r50, %r11, %r49;
	shr.s32 	%r13, %r50, 1;
	mad.lo.s32 	%r51, %r3, %r19, %r2;
	mul.lo.s32 	%r14, %r51, %r18;
	mov.f64 	%fd16, 0d0000000000000000;
	mov.u32 	%r64, 0;
	mov.f64 	%fd26, %fd16;

BB0_9:
	sub.s32 	%r16, %r12, %r64;
	setp.gt.s32	%p13, %r16, -1;
	setp.lt.s32	%p14, %r16, %r18;
	and.pred  	%p15, %p13, %p14;
	mov.f64 	%fd25, %fd16;
	@!%p15 bra 	BB0_11;
	bra.uni 	BB0_10;

BB0_10:
	shl.b32 	%r52, %r64, 1;
	mul.wide.s32 	%rd10, %r52, 8;
	add.s64 	%rd11, %rd2, %rd10;
	add.s32 	%r53, %r14, %r16;
	mul.wide.s32 	%rd12, %r53, 8;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.f64 	%fd18, [%rd13];
	ld.global.f64 	%fd19, [%rd11];
	mul.f64 	%fd6, %fd19, %fd18;
	mov.f64 	%fd25, %fd6;

BB0_11:
	mov.f64 	%fd7, %fd25;
	add.f64 	%fd26, %fd26, %fd7;
	add.s32 	%r64, %r64, 1;
	setp.lt.s32	%p16, %r64, %r13;
	mov.f64 	%fd24, %fd26;
	@%p16 bra 	BB0_9;

BB0_12:
	mad.lo.s32 	%r58, %r3, %r19, %r2;
	mad.lo.s32 	%r62, %r58, %r24, %r1;
	cvta.to.global.u64 	%rd14, %rd3;
	mul.wide.s32 	%rd15, %r62, 8;
	add.s64 	%rd16, %rd14, %rd15;
	st.global.f64 	[%rd16], %fd24;

BB0_13:
	ret;
}

	// .globl	_Z8upfirColPdS_S_iiii
.visible .entry _Z8upfirColPdS_S_iiii(
	.param .u64 _Z8upfirColPdS_S_iiii_param_0,
	.param .u64 _Z8upfirColPdS_S_iiii_param_1,
	.param .u64 _Z8upfirColPdS_S_iiii_param_2,
	.param .u32 _Z8upfirColPdS_S_iiii_param_3,
	.param .u32 _Z8upfirColPdS_S_iiii_param_4,
	.param .u32 _Z8upfirColPdS_S_iiii_param_5,
	.param .u32 _Z8upfirColPdS_S_iiii_param_6
)
{
	.reg .pred 	%p<17>;
	.reg .b32 	%r<65>;
	.reg .f64 	%fd<29>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd3, [_Z8upfirColPdS_S_iiii_param_0];
	ld.param.u64 	%rd4, [_Z8upfirColPdS_S_iiii_param_1];
	ld.param.u64 	%rd5, [_Z8upfirColPdS_S_iiii_param_2];
	ld.param.u32 	%r18, [_Z8upfirColPdS_S_iiii_param_3];
	ld.param.u32 	%r19, [_Z8upfirColPdS_S_iiii_param_4];
	ld.param.u32 	%r21, [_Z8upfirColPdS_S_iiii_param_5];
	ld.param.u32 	%r20, [_Z8upfirColPdS_S_iiii_param_6];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd5;
	shl.b32 	%r22, %r19, 1;
	add.s32 	%r23, %r22, %r20;
	add.s32 	%r24, %r23, -2;
	mov.u32 	%r25, %ntid.x;
	mov.u32 	%r26, %ctaid.x;
	mov.u32 	%r27, %tid.x;
	mad.lo.s32 	%r1, %r25, %r26, %r27;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mov.u32 	%r30, %tid.y;
	mad.lo.s32 	%r2, %r28, %r29, %r30;
	mov.u32 	%r31, %ntid.z;
	mov.u32 	%r32, %ctaid.z;
	mov.u32 	%r33, %tid.z;
	mad.lo.s32 	%r3, %r31, %r32, %r33;
	setp.lt.s32	%p1, %r1, %r18;
	setp.lt.s32	%p2, %r2, %r24;
	and.pred  	%p3, %p1, %p2;
	setp.lt.s32	%p4, %r3, %r21;
	and.pred  	%p5, %p3, %p4;
	@!%p5 bra 	BB1_13;
	bra.uni 	BB1_1;

BB1_1:
	and.b32  	%r34, %r2, 1;
	setp.eq.b32	%p6, %r34, 1;
	@!%p6 bra 	BB1_7;
	bra.uni 	BB1_2;

BB1_2:
	bfe.s32 	%r35, %r20, 0, 1;
	add.s32 	%r4, %r35, %r20;
	mov.f64 	%fd24, 0d0000000000000000;
	setp.lt.s32	%p7, %r4, 2;
	@%p7 bra 	BB1_12;

	add.s32 	%r37, %r2, -1;
	shr.u32 	%r38, %r37, 31;
	add.s32 	%r39, %r37, %r38;
	shr.s32 	%r5, %r39, 1;
	shr.u32 	%r40, %r4, 31;
	add.s32 	%r41, %r4, %r40;
	shr.s32 	%r6, %r41, 1;
	mul.lo.s32 	%r7, %r3, %r19;
	mov.f64 	%fd11, 0d0000000000000000;
	mov.u32 	%r63, 0;
	mov.f64 	%fd28, %fd11;

BB1_4:
	sub.s32 	%r9, %r5, %r63;
	setp.gt.s32	%p8, %r9, -1;
	setp.lt.s32	%p9, %r9, %r19;
	and.pred  	%p10, %p8, %p9;
	mov.f64 	%fd27, %fd11;
	@!%p10 bra 	BB1_6;
	bra.uni 	BB1_5;

BB1_5:
	shl.b32 	%r42, %r63, 1;
	mul.wide.s32 	%rd6, %r42, 8;
	add.s64 	%rd7, %rd2, %rd6;
	add.s32 	%r43, %r9, %r7;
	mad.lo.s32 	%r44, %r43, %r18, %r1;
	mul.wide.s32 	%rd8, %r44, 8;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.f64 	%fd13, [%rd9];
	ld.global.f64 	%fd14, [%rd7+8];
	mul.f64 	%fd2, %fd14, %fd13;
	mov.f64 	%fd27, %fd2;

BB1_6:
	mov.f64 	%fd3, %fd27;
	add.f64 	%fd28, %fd28, %fd3;
	add.s32 	%r63, %r63, 1;
	setp.lt.s32	%p11, %r63, %r6;
	mov.f64 	%fd24, %fd28;
	@%p11 bra 	BB1_4;
	bra.uni 	BB1_12;

BB1_7:
	and.b32  	%r45, %r20, 1;
	add.s32 	%r11, %r45, %r20;
	mov.f64 	%fd24, 0d0000000000000000;
	setp.lt.s32	%p12, %r11, 2;
	@%p12 bra 	BB1_12;

	shr.u32 	%r47, %r2, 31;
	add.s32 	%r48, %r2, %r47;
	shr.s32 	%r12, %r48, 1;
	shr.u32 	%r49, %r11, 31;
	add.s32 	%r50, %r11, %r49;
	shr.s32 	%r13, %r50, 1;
	mul.lo.s32 	%r14, %r3, %r19;
	mov.f64 	%fd16, 0d0000000000000000;
	mov.u32 	%r64, 0;
	mov.f64 	%fd26, %fd16;

BB1_9:
	sub.s32 	%r16, %r12, %r64;
	setp.gt.s32	%p13, %r16, -1;
	setp.lt.s32	%p14, %r16, %r19;
	and.pred  	%p15, %p13, %p14;
	mov.f64 	%fd25, %fd16;
	@!%p15 bra 	BB1_11;
	bra.uni 	BB1_10;

BB1_10:
	shl.b32 	%r51, %r64, 1;
	mul.wide.s32 	%rd10, %r51, 8;
	add.s64 	%rd11, %rd2, %rd10;
	add.s32 	%r52, %r16, %r14;
	mad.lo.s32 	%r53, %r52, %r18, %r1;
	mul.wide.s32 	%rd12, %r53, 8;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.f64 	%fd18, [%rd13];
	ld.global.f64 	%fd19, [%rd11];
	mul.f64 	%fd6, %fd19, %fd18;
	mov.f64 	%fd25, %fd6;

BB1_11:
	mov.f64 	%fd7, %fd25;
	add.f64 	%fd26, %fd26, %fd7;
	add.s32 	%r64, %r64, 1;
	setp.lt.s32	%p16, %r64, %r13;
	mov.f64 	%fd24, %fd26;
	@%p16 bra 	BB1_9;

BB1_12:
	mad.lo.s32 	%r61, %r3, %r24, %r2;
	mad.lo.s32 	%r62, %r61, %r18, %r1;
	cvta.to.global.u64 	%rd14, %rd3;
	mul.wide.s32 	%rd15, %r62, 8;
	add.s64 	%rd16, %rd14, %rd15;
	st.global.f64 	[%rd16], %fd24;

BB1_13:
	ret;
}

	// .globl	_Z8upfirBeaPdS_S_iiii
.visible .entry _Z8upfirBeaPdS_S_iiii(
	.param .u64 _Z8upfirBeaPdS_S_iiii_param_0,
	.param .u64 _Z8upfirBeaPdS_S_iiii_param_1,
	.param .u64 _Z8upfirBeaPdS_S_iiii_param_2,
	.param .u32 _Z8upfirBeaPdS_S_iiii_param_3,
	.param .u32 _Z8upfirBeaPdS_S_iiii_param_4,
	.param .u32 _Z8upfirBeaPdS_S_iiii_param_5,
	.param .u32 _Z8upfirBeaPdS_S_iiii_param_6
)
{
	.reg .pred 	%p<17>;
	.reg .b32 	%r<56>;
	.reg .f64 	%fd<27>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd3, [_Z8upfirBeaPdS_S_iiii_param_0];
	ld.param.u64 	%rd4, [_Z8upfirBeaPdS_S_iiii_param_1];
	ld.param.u64 	%rd5, [_Z8upfirBeaPdS_S_iiii_param_2];
	ld.param.u32 	%r14, [_Z8upfirBeaPdS_S_iiii_param_3];
	ld.param.u32 	%r15, [_Z8upfirBeaPdS_S_iiii_param_4];
	ld.param.u32 	%r16, [_Z8upfirBeaPdS_S_iiii_param_5];
	ld.param.u32 	%r17, [_Z8upfirBeaPdS_S_iiii_param_6];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd5;
	shl.b32 	%r18, %r16, 1;
	add.s32 	%r19, %r17, %r18;
	add.s32 	%r20, %r19, -2;
	mov.u32 	%r21, %ntid.x;
	mov.u32 	%r22, %ctaid.x;
	mov.u32 	%r23, %tid.x;
	mad.lo.s32 	%r1, %r21, %r22, %r23;
	mov.u32 	%r24, %ntid.y;
	mov.u32 	%r25, %ctaid.y;
	mov.u32 	%r26, %tid.y;
	mad.lo.s32 	%r2, %r24, %r25, %r26;
	mov.u32 	%r27, %ntid.z;
	mov.u32 	%r28, %ctaid.z;
	mov.u32 	%r29, %tid.z;
	mad.lo.s32 	%r3, %r27, %r28, %r29;
	setp.lt.s32	%p1, %r1, %r14;
	setp.lt.s32	%p2, %r2, %r15;
	and.pred  	%p3, %p1, %p2;
	setp.lt.s32	%p4, %r3, %r20;
	and.pred  	%p5, %p3, %p4;
	@!%p5 bra 	BB2_11;
	bra.uni 	BB2_1;

BB2_1:
	and.b32  	%r30, %r3, 1;
	setp.eq.b32	%p6, %r30, 1;
	@!%p6 bra 	BB2_6;
	bra.uni 	BB2_2;

BB2_2:
	add.s32 	%r32, %r3, -1;
	shr.u32 	%r33, %r32, 31;
	add.s32 	%r34, %r32, %r33;
	shr.s32 	%r4, %r34, 1;
	bfe.s32 	%r35, %r17, 0, 1;
	add.s32 	%r36, %r35, %r17;
	shr.u32 	%r37, %r36, 31;
	add.s32 	%r38, %r36, %r37;
	shr.s32 	%r5, %r38, 1;
	mov.f64 	%fd24, 0d0000000000000000;
	mov.f64 	%fd26, %fd24;
	mov.u32 	%r54, 0;
	setp.lt.s32	%p7, %r36, 2;
	@%p7 bra 	BB2_10;

BB2_3:
	sub.s32 	%r7, %r4, %r54;
	setp.gt.s32	%p8, %r7, -1;
	setp.lt.s32	%p9, %r7, %r16;
	and.pred  	%p10, %p8, %p9;
	mov.f64 	%fd20, 0d0000000000000000;
	@!%p10 bra 	BB2_5;
	bra.uni 	BB2_4;

BB2_4:
	shl.b32 	%r39, %r54, 1;
	mul.wide.s32 	%rd6, %r39, 8;
	add.s64 	%rd7, %rd2, %rd6;
	mad.lo.s32 	%r40, %r7, %r15, %r2;
	mad.lo.s32 	%r41, %r40, %r14, %r1;
	mul.wide.s32 	%rd8, %r41, 8;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.f64 	%fd13, [%rd9];
	ld.global.f64 	%fd14, [%rd7+8];
	mul.f64 	%fd20, %fd14, %fd13;

BB2_5:
	add.f64 	%fd26, %fd26, %fd20;
	add.s32 	%r54, %r54, 1;
	setp.lt.s32	%p11, %r54, %r5;
	mov.f64 	%fd24, %fd26;
	@%p11 bra 	BB2_3;
	bra.uni 	BB2_10;

BB2_6:
	shr.u32 	%r43, %r3, 31;
	add.s32 	%r44, %r3, %r43;
	shr.s32 	%r9, %r44, 1;
	and.b32  	%r45, %r17, 1;
	add.s32 	%r46, %r45, %r17;
	shr.u32 	%r47, %r46, 31;
	add.s32 	%r48, %r46, %r47;
	shr.s32 	%r10, %r48, 1;
	mov.f64 	%fd24, 0d0000000000000000;
	mov.f64 	%fd25, %fd24;
	mov.u32 	%r55, 0;
	setp.lt.s32	%p12, %r46, 2;
	@%p12 bra 	BB2_10;

BB2_7:
	sub.s32 	%r12, %r9, %r55;
	setp.gt.s32	%p13, %r12, -1;
	setp.lt.s32	%p14, %r12, %r16;
	and.pred  	%p15, %p13, %p14;
	mov.f64 	%fd21, 0d0000000000000000;
	@!%p15 bra 	BB2_9;
	bra.uni 	BB2_8;

BB2_8:
	shl.b32 	%r49, %r55, 1;
	mul.wide.s32 	%rd10, %r49, 8;
	add.s64 	%rd11, %rd2, %rd10;
	mad.lo.s32 	%r50, %r12, %r15, %r2;
	mad.lo.s32 	%r51, %r50, %r14, %r1;
	mul.wide.s32 	%rd12, %r51, 8;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.f64 	%fd18, [%rd13];
	ld.global.f64 	%fd19, [%rd11];
	mul.f64 	%fd21, %fd19, %fd18;

BB2_9:
	add.f64 	%fd25, %fd25, %fd21;
	add.s32 	%r55, %r55, 1;
	setp.lt.s32	%p16, %r55, %r10;
	mov.f64 	%fd24, %fd25;
	@%p16 bra 	BB2_7;

BB2_10:
	mad.lo.s32 	%r52, %r3, %r15, %r2;
	mad.lo.s32 	%r53, %r52, %r14, %r1;
	cvta.to.global.u64 	%rd14, %rd3;
	mul.wide.s32 	%rd15, %r53, 8;
	add.s64 	%rd16, %rd14, %rd15;
	st.global.f64 	[%rd16], %fd24;

BB2_11:
	ret;
}


